# Enhanced Multi-Agent Stock Research Architecture

### Phase 0: Initialization & Planning

These run first, all other tasks depend on them.

**User Interaction:**

Prompt: "Enter stock ticker to analyze:"
User: "AAPL"

@validator:

1. Confirm valid ticker using yfinance or stock-symbol-server
2. Get basic info: company name, sector, market cap
3. Display: "Analyzing Apple Inc. (AAPL) - Technology - $2.8T market cap"

Show standard outline (8 sections from your spec):

1. Short summary / overall assessment
2. Stock chart, technicals, comparison v. Peers, sankey of income statement
3. Company Profile
4.  Business Model  
5. Competitive Landscape
6. Supply Chain Positioning
7. Financial and Operating Leverage
8. Valuation
9. Recent Developments and Risk Factors
10. SWOT analysis, bull and bear case
11. Overall Assessment and critical watch points

Ask: "Any additional questions or custom sections?"

User can:

- Add custom sections: "Add section on R&D innovation"
- Modify existing: "Expand valuation to include scenario analysis"
- Skip sections: "Skip supply chain positioning"

Show updated outline, iterate until user confirms.



### Phase 1: Evergreen Tasks (Parallel Foundation Layer)

**Launch Orchestrator with Initial Task Queue:**



```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EVERGREEN TASKS (No dependencies - launch immediately)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@evergreen-1: Company Profile Baseline
â”œâ”€ Tools: yfinance, web_search, web_fetch, wikipedia MCP
â”œâ”€ Prompt: |
â”‚   Gather baseline company information:
â”‚   - Fetch 10-K Item 1 (Business Description)
â”‚   - Yahoo Finance company profile
â”‚   - Wikipedia overview
â”‚   - Perplexity search for recent company summary
â”œâ”€ Output: Raw text â†’ Parse â†’ Store
â”‚   - Facts â†’ Knowledge Graph (entities, relationships)
â”‚   - Text chunks â†’ Vector Store (embeddings)
â”‚   - Structured data â†’ SQLite (company_profile table)
â”œâ”€ Budget: 100K tokens max
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-2: Comparables Identification
â”œâ”€ Tools: openbb, finviz, yfinance
â”œâ”€ Prompt: |
â”‚   Identify peer companies:
â”‚   - Get industry peers from OpenBB
â”‚   - Validate using Finviz screener (same sector, similar market cap)
â”‚   - Confirm top 5-7 comparables
â”œâ”€ Output:
â”‚   - Store peer list â†’ mem0 (persistent memory)
â”‚   - Store peer metadata â†’ SQLite (comparables table)
â”‚   - Create relationships â†’ Knowledge Graph (AAPL-[COMPETES_WITH]->MSFT)
â”œâ”€ Budget: 50K tokens
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-3: Fundamental Data Collection
â”œâ”€ Dependencies: @evergreen-2 (needs comparable list)
â”œâ”€ Tools: yfinance, finviz, openbb, stock-symbol-server
â”œâ”€ Prompt: |
â”‚   Collect financial data for target + comparables:
â”‚   - Income statements (5 years)
â”‚   - Balance sheets (5 years)
â”‚   - Cash flows (5 years)
â”‚   - Key ratios: P/E, PEG, P/B, ROE, ROIC, etc.
â”‚   - Growth metrics: Revenue CAGR, EPS growth
â”œâ”€ Output:
â”‚   - Store all metrics â†’ SQLite (fundamentals table)
â”‚   - Create calculated ratios â†’ Knowledge Graph
â”‚   - Time series data â†’ SQLite (for charts)
â”œâ”€ Budget: 80K tokens
â””â”€ Status: WAITING â†’ RUNNING â†’ COMPLETE

@evergreen-4: Technical Analysis
â”œâ”€ Tools: stock-symbol-server (technical_analysis, make_stock_chart)
â”œâ”€ Prompt: |
â”‚   Analyze technical position:
â”‚   - Generate price chart (1 year + 5 year)
â”‚   - Calculate indicators: SMA(50, 200), RSI, MACD, Bollinger Bands
â”‚   - Identify trend: uptrend/downtrend/sideways
â”‚   - Support/resistance levels
â”‚   - Volume analysis
â”œâ”€ Output:
â”‚   - Charts â†’ Save to ./charts/
â”‚   - Indicators table â†’ SQLite
â”‚   - Trend assessment â†’ Knowledge Graph (AAPL-[HAS_TREND]->"Uptrend")
â”œâ”€ Budget: 40K tokens
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-5: Deep News Search
â”œâ”€ Tools: web_search, web_fetch, yfinance (get_yahoo_finance_news)
â”œâ”€ Prompt: |
â”‚   Comprehensive news search (past 6 months):
â”‚   - Recent earnings announcements
â”‚   - Product launches/failures
â”‚   - M&A activity, partnerships
â”‚   - Regulatory issues, lawsuits
â”‚   - Short-seller reports (Hindenburg, Citron, etc.)
â”‚   - Executive changes
â”‚   - Major customer wins/losses
â”‚   
â”‚   For EACH article found:
â”‚   1. Extract key facts (per sentence)
â”‚   2. Evaluate: Is this relevant? Non-trivial? Material?
â”‚   3. If yes â†’ Store in Knowledge Graph with metadata
â”‚   4. Store full paragraph â†’ Vector Store (for retrieval)
â”œâ”€ Output:
â”‚   - News items â†’ SQLite (news table with sentiment, materiality)
â”‚   - Facts â†’ Knowledge Graph
â”‚   - Text â†’ Vector Store
â”œâ”€ Budget: 150K tokens
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-6: Sell-Side Research
â”œâ”€ Tools: web_search, web_fetch
â”œâ”€ Prompt: |
â”‚   Find sell-side analyst research:
â”‚   - Search for recent analyst reports (JPM, GS, MS, etc.)
â”‚   - Morningstar analysis
â”‚   - Seeking Alpha summaries
â”‚   - Bloomberg/Reuters analyst consensus
â”‚   
â”‚   Extract from each:
â”‚   - Price targets and ratings
â”‚   - Key thesis points (bull/bear)
â”‚   - Concerns or risks highlighted
â”‚   - Valuation methodologies used
â”œâ”€ Output:
â”‚   - Analyst data â†’ SQLite (analyst_coverage table)
â”‚   - Consensus metrics â†’ Knowledge Graph
â”‚   - Report excerpts â†’ Vector Store
â”œâ”€ Budget: 100K tokens
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-7: SEC Filings Deep Dive
â”œâ”€ Tools: web_search (SEC EDGAR), web_fetch, custom SEC MCP if available
â”œâ”€ Prompt: |
â”‚   Analyze key SEC filings:
â”‚   - Latest 10-K: Item 1 (Business), Item 1A (Risk Factors), Item 7 (MD&A)
â”‚   - Latest 10-Q: Recent developments, updated risks
â”‚   - Recent 8-Ks: Material events
â”‚   - DEF 14A (Proxy): Executive comp, governance
â”‚   
â”‚   Extract and structure:
â”‚   - Business segments â†’ Knowledge Graph
â”‚   - Risk factors â†’ SQLite + Knowledge Graph
â”‚   - MD&A insights â†’ Vector Store
â”‚   - Governance details â†’ SQLite
â”œâ”€ Output:
â”‚   - Structured data â†’ SQLite (filings table)
â”‚   - Entities/relationships â†’ Knowledge Graph  
â”‚   - Long-form text â†’ Vector Store
â”œâ”€ Budget: 200K tokens (filings are long)
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-8: Universal MCP Data Pull
â”œâ”€ Tools: Jeff Emanuel's large universal MCP server (from your context)
â”œâ”€ Prompt: |
â”‚   Query comprehensive data sources:
â”‚   - Market data feeds
â”‚   - Alternative data sources
â”‚   - Institutional ownership
â”‚   - Options flow data
â”‚   - Any other relevant data endpoints
â”œâ”€ Output: Store all retrieved data appropriately
â”œâ”€ Budget: 80K tokens
â””â”€ Status: RUNNING â†’ COMPLETE

@evergreen-9: Previous Tearsheet Review
â”œâ”€ Tools: local file access
â”œâ”€ Prompt: |
â”‚   If we've analyzed this company before:
â”‚   - Load previous tearsheet
â”‚   - Extract still-relevant information
â”‚   - Note what's changed since last analysis
â”‚   - Identify areas needing fresh research
â”œâ”€ Output:
â”‚   - Previous insights â†’ Vector Store (marked as "historical")
â”‚   - Change deltas â†’ Knowledge Graph
â”œâ”€ Budget: 50K tokens
â””â”€ Status: RUNNING â†’ COMPLETE
```

### Knowledge Storage Architecture

python

```python
# SQLite Schema
"""
companies(
    ticker TEXT PRIMARY KEY,
    name TEXT,
    sector TEXT,
    industry TEXT,
    market_cap REAL,
    description TEXT
)

comparables(
    ticker TEXT,
    peer_ticker TEXT,
    similarity_score REAL,
    basis TEXT  -- 'industry', 'size', 'business_model'
)

fundamentals(
    ticker TEXT,
    metric_name TEXT,
    period DATE,
    value REAL,
    PRIMARY KEY(ticker, metric_name, period)
)

news(
    news_id INTEGER PRIMARY KEY,
    ticker TEXT,
    headline TEXT,
    content TEXT,
    source TEXT,
    pub_date DATE,
    sentiment REAL,  -- -1 to 1
    materiality INTEGER  -- 1-5 scale
)

analyst_coverage(
    ticker TEXT,
    firm TEXT,
    analyst TEXT,
    rating TEXT,  -- 'Buy', 'Hold', 'Sell'
    price_target REAL,
    date DATE
)

knowledge_facts(
    fact_id INTEGER PRIMARY KEY,
    subject TEXT,
    predicate TEXT,
    object TEXT,
    source TEXT,
    confidence REAL,
    timestamp DATE
)
"""

# Knowledge Graph (Neo4j-style or in-memory)
"""
Nodes: Company, Person, Product, Risk, Event
Relationships: COMPETES_WITH, SUPPLIES_TO, ACQUIRED, HAS_RISK, etc.

Example:
(AAPL:Company)-[COMPETES_WITH]->(MSFT:Company)
(AAPL:Company)-[HAS_PRODUCT]->(iPhone:Product)
(iPhone:Product)-[GENERATES_REVENUE {percentage: 52}]->(AAPL:Company)
(AAPL:Company)-[HAS_RISK {severity: 'high'}]->(China_Dependence:Risk)
"""

# Vector Store (ChromaDB)
"""
Collections:
- company_descriptions: Long-form company overviews
- news_articles: News content with metadata
- analyst_reports: Excerpts from research reports
- filings: SEC filing text chunks
- historical_analysis: Previous tearsheets

Each embedding includes metadata:
{
    'source': 'news' | 'filing' | 'analyst' | 'web',
    'date': '2025-01-14',
    'ticker': 'AAPL',
    'confidence': 0.9,
    'section_relevance': ['business_model', 'risks']
}
"""
```

### Phase 2: Section Agents (With Critic-Optimizer Loops)

Each section agent follows this pattern:

```markdown
@section-agent-{name}:
â”œâ”€ Dependencies: ALL evergreen tasks must be COMPLETE
â”œâ”€ Budget: 150K tokens, max 3 iterations
â””â”€ Process Flow:

STEP 1: INITIAL RETRIEVAL
â”œâ”€ Query SQLite for structured data relevant to section
â”œâ”€ Query Knowledge Graph for relationships
â”œâ”€ Query Vector Store (semantic search) for contextual info
â””â”€ Assemble retrieval results

STEP 2: DRAFT INITIAL SECTION
â”œâ”€ Use section-specific prompt template
â”œâ”€ Incorporate retrieved data
â”œâ”€ Write comprehensive first draft
â””â”€ Save to ./drafts/{section_name}_v1.md

STEP 3: CRITIC EVALUATION
â”œâ”€ Prompt: |
â”‚   You are a sophisticated Wall Street research analyst reviewing this section.
â”‚   Evaluate on:
â”‚   - **Completeness**: Are key questions answered? What's missing?
â”‚   - **Data Support**: Are claims backed by specific data?
â”‚   - **Insight Depth**: Surface-level or deep analysis?
â”‚   - **Clarity**: Is it clear and well-structured?
â”‚   - **Accuracy**: Any potential errors or inconsistencies?
â”‚   
â”‚   Provide:
â”‚   1. Quality score (0-100)
â”‚   2. Specific gaps or weaknesses
â”‚   3. Questions that remain unanswered
â”‚   4. Suggested improvements
â”œâ”€ Output: Critic evaluation saved to ./critique/{section_name}_critique.json
â””â”€ Decision:
    â”œâ”€ If score â‰¥ 85 AND no major gaps â†’ COMPLETE
    â””â”€ Else â†’ Continue to STEP 4

STEP 4: GAP ANALYSIS & SEARCH PLAN
â”œâ”€ Based on critic evaluation, identify information gaps
â”œâ”€ Generate search plan:
â”‚   - What specific data is missing?
â”‚   - Which tools/sources to query?
â”‚   - What questions to answer?
â”œâ”€ Example search plan:
â”‚   {
â”‚     "gaps": [
â”‚       "Need gross margin trends for past 5 years",
â”‚       "Missing CEO's strategic vision from recent interviews",
â”‚       "Unclear on R&D spending as % of revenue"
â”‚     ],
â”‚     "search_steps": [
â”‚       {"tool": "sqlite", "query": "SELECT ... FROM fundamentals WHERE metric='gross_margin'"},
â”‚       {"tool": "web_search", "query": "Tim Cook interview strategy 2024"},
â”‚       {"tool": "knowledge_graph", "query": "MATCH (c:Company)-[r:SPENDS_ON]->(rd:RnD)"}
â”‚     ]
â”‚   }
â””â”€ Save to ./search_plans/{section_name}_search_plan.json

STEP 5: EXECUTE SEARCH PLAN
â”œâ”€ For each search step in plan:
â”‚   â”œâ”€ Execute tool/query
â”‚   â”œâ”€ Extract relevant information
â”‚   â”œâ”€ Store new findings (if novel):
â”‚   â”‚   â”œâ”€ SQLite (structured data)
â”‚   â”‚   â”œâ”€ Knowledge Graph (facts/relationships)
â”‚   â”‚   â””â”€ Vector Store (text chunks)
â”‚   â””â”€ Accumulate results
â””â”€ Return filled gaps

STEP 6: REWRITE SECTION
â”œâ”€ Incorporate new information from search execution
â”œâ”€ Address specific weaknesses from critic
â”œâ”€ Improve clarity, depth, data support
â”œâ”€ Save to ./drafts/{section_name}_v{N}.md
â””â”€ Increment iteration counter

STEP 7: ITERATION CHECK
â”œâ”€ If iterations < max_iterations (3):
â”‚   â””â”€ Return to STEP 3 (Critic Evaluation)
â”œâ”€ Else if budget exceeded:
â”‚   â””â”€ Save best version, mark COMPLETE
â””â”€ Else:
    â””â”€ Mark COMPLETE

OUTPUT:
â”œâ”€ Final section: ./sections/{section_name}.md
â”œâ”€ Metadata: ./metadata/{section_name}_meta.json
â”‚   {
â”‚     "iterations": 2,
â”‚     "final_score": 88,
â”‚     "tokens_used": 142000,
â”‚     "gaps_remaining": ["Long-term guidance unclear"],
â”‚     "data_sources": ["10-K", "Yahoo Finance", "3 news articles", "2 analyst reports"]
â”‚   }
â””â”€ Status: COMPLETE
```

### Specific Section Agent Configurations

```markdown
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 1: COMPANY PROFILE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-company-profile:
â”œâ”€ Dependencies: evergreen-1, evergreen-4, evergreen-7
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: company basics, financial summary
â”‚   - Knowledge Graph: founding history, key milestones, current structure
â”‚   - Vector Store: "company history", "business overview"
â”œâ”€ Draft Prompt: |
â”‚   Write comprehensive company profile including:
â”‚   
â”‚   **History & Origin Story:**
â”‚   - Founding story with key dates
â”‚   - Pivotal moments that shaped the company
â”‚   - Evolution of business model
â”‚   
â”‚   **Core Business & Competitors:**
â”‚   - Primary products/services (revenue breakdown)
â”‚   - Target markets and customers
â”‚   - Direct competitors (name top 5 with brief comparison)
â”‚   
â”‚   **Recent Major Developments:**
â”‚   - Last 12 months: M&A, product launches, strategic shifts
â”‚   - Upcoming catalysts or events
â”‚   
â”‚   **Stock Chart:**
â”‚   - Embed chart image from ./charts/
â”‚   - Brief commentary on technical position
â”‚   
â”‚   **Technical Indicators Table:**
â”‚   | Indicator | Value | Signal |
â”‚   |-----------|-------|--------|
â”‚   | 50-day SMA | $XXX | Above/Below price |
â”‚   | 200-day SMA | $XXX | Golden/Death cross |
â”‚   | RSI | XX | Overbought/Oversold/Neutral |
â”‚   | MACD | X.XX | Bullish/Bearish |
â”‚   
â”‚   **Key Fundamental Ratios Table:**
â”‚   | Metric | TICKER | Peer Avg | Industry |
â”‚   |--------|--------|----------|----------|
â”‚   | P/E | XX.X | XX.X | XX.X |
â”‚   | P/B | X.X | X.X | X.X |
â”‚   | ROE | XX% | XX% | XX% |
â”‚   | Debt/Equity | X.X | X.X | X.X |
â”‚   | Rev Growth (3yr) | XX% | XX% | XX% |
â”‚   
â”‚   **Income Statement Sankey Chart:**
â”‚   - Create Sankey diagram showing revenue flow through income statement
â”‚   - Revenue â†’ COGS â†’ Gross Profit â†’ OpEx categories â†’ Net Income
â”‚   - Save visualization to ./charts/sankey_income.png
â”‚   
â”‚   Use specific data from knowledge stores. Cite sources.
â”‚   Target: 1500-2000 words
â”œâ”€ Critic Focus:
â”‚   - Origin story compelling and factual?
â”‚   - Competitor comparison fair and data-backed?
â”‚   - Recent developments truly material?
â”‚   - All tables complete with accurate data?
â”‚   - Charts properly embedded and explained?
â””â”€ Budget: 150K tokens, 3 iterations max

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 2: COMPANY BUSINESS MODEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-business-model:
â”œâ”€ Dependencies: evergreen-1, evergreen-3, evergreen-7
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: revenue breakdown by segment, customer data
â”‚   - Knowledge Graph: (Company)-[OFFERS]->(Products), (Products)-[GENERATES]->(Revenue)
â”‚   - Vector Store: "business model", "revenue streams", "monetization"
â”œâ”€ Draft Prompt: |
â”‚   Analyze business model in three parts:
â”‚   
â”‚   **Core Businesses, Products & Services:**
â”‚   - Enumerate all major business lines
â”‚   - For each: description, target market, scale
â”‚   - Revenue contribution (% of total)
â”‚   
â”‚   **Revenue & Monetization:**
â”‚   - Primary revenue streams with specifics
â”‚   - Customer segments (consumer/enterprise/government)
â”‚   - Pricing models (subscription/transaction/licensing)
â”‚   - Key partnerships or channels
â”‚   - Unit economics if available
â”‚   
â”‚   **Competitive Advantages (Moats):**
â”‚   Assess presence and strength of:
â”‚   - Network effects (direct/indirect)
â”‚   - Switching costs (contractual/technical/data)
â”‚   - Regulatory moats (licenses, patents, trade secrets)
â”‚   - Brand value (pricing power evidence)
â”‚   - Proprietary technology (hard to replicate)
â”‚   - Distribution advantages (exclusive channels, scale)
â”‚   
â”‚   For each moat: Rate strength (Weak/Moderate/Strong)
â”‚   Provide evidence from filings, news, analyst reports
â”‚   
â”‚   Target: 1200-1500 words
â”œâ”€ Critic Focus:
â”‚   - Business model clearly explained?
â”‚   - Revenue breakdown accurate and detailed?
â”‚   - Moat analysis rigorous (evidence-based, not aspirational)?
â”‚   - Customer segments well-defined?
â””â”€ Budget: 150K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 3: COMPETITIVE LANDSCAPE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-competitive-landscape:
â”œâ”€ Dependencies: evergreen-2, evergreen-3, evergreen-6
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: competitor metrics, market shares
â”‚   - Knowledge Graph: (Company)-[COMPETES_WITH]->(Competitor) relationships
â”‚   - Vector Store: "competitive positioning", "market share", competitor names
â”œâ”€ Draft Prompt: |
â”‚   **Main Competitors:**
â”‚   Identify and analyze:
â”‚   - Direct competitors (same products/markets)
â”‚   - Adjacent competitors (partial overlap)
â”‚   - Emerging competitors (disruptive threats)
â”‚   
â”‚   For top 5-7 competitors:
â”‚   
â”‚   **Competitive Metrics Comparison Table:**
â”‚   | Metric | TICKER | Comp 1 | Comp 2 | Comp 3 | Comp 4 |
â”‚   |--------|--------|--------|--------|--------|--------|
â”‚   | Market Share | X% | X% | X% | X% | X% |
â”‚   | Revenue Growth (3Y) | XX% | XX% | XX% | XX% | XX% |
â”‚   | Gross Margin | XX% | XX% | XX% | XX% | XX% |
â”‚   | R&D as % Revenue | XX% | XX% | XX% | XX% | XX% |
â”‚   | P/E Ratio | XX | XX | XX | XX | XX |
â”‚   | EV/Sales | X.X | X.X | X.X | X.X | X.X |
â”‚   
â”‚   **Competitive Analysis:**
â”‚   - Product differentiation: What makes each unique?
â”‚   - Pricing power: Who can raise prices? Evidence?
â”‚   - Growth trajectories: Who's gaining/losing share?
â”‚   - Innovation pace: R&D spend, patent activity
â”‚   - Customer loyalty metrics if available
â”‚   
â”‚   **Strategic Positioning:**
â”‚   - Where does target company excel vs competitors?
â”‚   - Where is it vulnerable?
â”‚   - Likely competitive moves (pricing, M&A, new products)
â”‚   
â”‚   Use analyst reports and recent news for qualitative insights.
â”‚   Target: 1200-1500 words
â”œâ”€ Critic Focus:
â”‚   - Comprehensive competitor identification?
â”‚   - Metrics table complete and accurate?
â”‚   - Analysis goes beyond surface comparisons?
â”‚   - Strategic implications clear?
â””â”€ Budget: 150K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 4: SUPPLY CHAIN POSITIONING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-supply-chain:
â”œâ”€ Dependencies: evergreen-1, evergreen-5, evergreen-7
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: supplier data, distribution partners
â”‚   - Knowledge Graph: (Company)-[SOURCES_FROM]->(Supplier), (Company)-[DISTRIBUTES_VIA]->(Channel)
â”‚   - Vector Store: "supply chain", "suppliers", "distribution"
â”œâ”€ Draft Prompt: |
â”‚   **Upstream (Supplier-Side):**
â”‚   - Key suppliers (top 5-10 by importance)
â”‚   - Raw materials or components sourced
â”‚   - Geographic concentration (single-country risk?)
â”‚   - Supplier bargaining power assessment
â”‚   - Supplier dependencies or lock-ins
â”‚   
â”‚   **Downstream (Customer/Distribution-Side):**
â”‚   - Distribution channels (direct, retail, online, partners)
â”‚   - Key distribution partners
â”‚   - Customer concentration (top customers as % of revenue)
â”‚   - Customer bargaining power
â”‚   
â”‚   **Supply Chain Risks:**
â”‚   - Single points of failure
â”‚   - Geographic concentration risks
â”‚   - Inventory management approach (JIT vs buffer stock)
â”‚   - Recent supply chain disruptions (from news search)
â”‚   
â”‚   **Supply Chain Advantages:**
â”‚   - Vertical integration benefits
â”‚   - Exclusive supplier relationships
â”‚   - Superior logistics/distribution
â”‚   
â”‚   Target: 1000-1200 words
â”œâ”€ Critic Focus:
â”‚   - Key dependencies identified?
â”‚   - Risk assessment thorough?
â”‚   - Upstream and downstream balanced coverage?
â””â”€ Budget: 120K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 5: FINANCIAL AND OPERATING LEVERAGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-leverage:
â”œâ”€ Dependencies: evergreen-3, evergreen-7
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: balance sheet data, debt metrics, cost structure
â”‚   - Knowledge Graph: financial relationships
â”‚   - Vector Store: "leverage", "debt", "fixed costs", "operating leverage"
â”œâ”€ Draft Prompt: |
â”‚   **Financial Leverage:**
â”‚   - Total debt levels (absolute and as % of equity, EBITDA)
â”‚   - Debt maturity schedule (near-term obligations)
â”‚   - Interest coverage ratio (EBIT / Interest Expense)
â”‚   - Credit ratings (S&P, Moody's, Fitch)
â”‚   - Cost of debt (weighted average interest rate)
â”‚   - Debt covenants or restrictions
â”‚   
â”‚   **Financial Leverage Table:**
â”‚   | Metric | Current | 3Y Avg | Peer Avg |
â”‚   |--------|---------|--------|----------|
â”‚   | Debt/Equity | X.X | X.X | X.X |
â”‚   | Debt/EBITDA | X.X | X.X | X.X |
â”‚   | Interest Coverage | X.X | X.X | X.X |
â”‚   | Current Ratio | X.X | X.X | X.X |
â”‚   
â”‚   **Operating Leverage:**
â”‚   - Fixed vs variable cost structure
â”‚   - Operating leverage calculation (% change EBIT / % change Sales)
â”‚   - Margin sensitivity: If revenue grows 10%, what happens to EBIT margin?
â”‚   - Scalability: Can they grow revenue without proportional cost increases?
â”‚   - Breakeven analysis if data available
â”‚   
â”‚   **Assessment:**
â”‚   - Is financial leverage appropriate for business model?
â”‚   - Refinancing risks or opportunities?
â”‚   - Operating leverage as competitive advantage or vulnerability?
â”‚   
â”‚   Target: 1000-1200 words
â”œâ”€ Critic Focus:
â”‚   - Leverage metrics comprehensive and accurate?
â”‚   - Operating leverage analysis quantitative, not hand-wavy?
â”‚   - Peer comparison meaningful?
â””â”€ Budget: 120K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 6: VALUATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-valuation:
â”œâ”€ Dependencies: evergreen-3, evergreen-6
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: historical/projected financials, comp multiples
â”‚   - Knowledge Graph: valuation-related facts
â”‚   - Vector Store: "valuation", "DCF", analyst price targets
â”œâ”€ Draft Prompt: |
â”‚   **Valuation Methodologies:**
â”‚   
â”‚   **1. Market-Based (Comparables):**
â”‚   - Current trading multiples vs peers
â”‚   - P/E, P/B, EV/EBITDA, EV/Sales, PEG
â”‚   - Historical valuation ranges (5-year)
â”‚   - Premium/discount to peers (justified or not?)
â”‚   
â”‚   **Comps Valuation Table:**
â”‚   | Multiple | TICKER | Peer Median | Implied Value |
â”‚   |----------|--------|-------------|---------------|
â”‚   | P/E (NTM) | XX.X | XX.X | $XXX |
â”‚   | EV/EBITDA | XX.X | XX.X | $XXX |
â”‚   | P/Sales | X.X | X.X | $XXX |
â”‚   | PEG | X.X | X.X | $XXX |
â”‚   
â”‚   **2. Income-Based (DCF):**
â”‚   - Key assumptions to discuss:
â”‚     * Revenue growth rates (near-term, long-term)
â”‚     * Margin expansion or compression
â”‚     * Reinvestment requirements (capex, working capital)
â”‚     * Terminal growth rate
â”‚     * Discount rate (WACC calculation)
â”‚   - Sensitivity analysis: What if growth is Â±2%? WACC Â±1%?
â”‚   - Range of intrinsic values under different scenarios
â”‚   
â”‚   **3. Asset-Based:**
â”‚   - Book value per share
â”‚   - Tangible book value
â”‚   - Sum-of-the-parts if applicable (multiple business segments)
â”‚   - Relevant for asset-heavy businesses
â”‚   
â”‚   **4. LBO Analysis (if relevant):**
â”‚   - Could private equity acquire at current price?
â”‚   - IRR at various exit multiples
â”‚   - Debt capacity
â”‚   
â”‚   **Analyst Price Targets:**
â”‚   - Consensus target (from sell-side)
â”‚   - Range of targets (high/low)
â”‚   - Typical methodologies analysts use
â”‚   
â”‚   **Valuation Assessment:**
â”‚   - Which methodology most appropriate for this company? Why?
â”‚   - Fair value estimate range
â”‚   - Current valuation attractive/expensive/fair?
â”‚   - Key sensitivities (what drives valuation most?)
â”‚   
â”‚   Target: 1500-1800 words
â”œâ”€ Critic Focus:
â”‚   - All major methodologies covered?
â”‚   - Assumptions clearly stated and reasonable?
â”‚   - Sensitivity analysis provided?
â”‚   - Conclusion balanced (not overly bullish/bearish)?
â””â”€ Budget: 180K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 7: NEWS SEARCH AND RISK FACTORS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-news-risks:
â”œâ”€ Dependencies: evergreen-5, evergreen-7
â”œâ”€ Initial Retrieval:
â”‚   - SQLite: news items (last 6-12 months), filtered by materiality
â”‚   - Knowledge Graph: (Company)-[HAS_RISK]->(Risk) nodes
â”‚   - Vector Store: "risk factors", "lawsuit", "investigation", "controversy"
â”œâ”€ Draft Prompt: |
â”‚   **Recent News Themes:**
â”‚   Categorize and summarize news from past 6-12 months:
â”‚   
â”‚   **Positive Developments:**
â”‚   - Product launches (reception, early metrics)
â”‚   - Partnerships or strategic alliances
â”‚   - Large customer wins
â”‚   - Regulatory approvals
â”‚   - Beat earnings expectations
â”‚   - Innovation announcements
â”‚   
â”‚   **Negative Developments:**
â”‚   - Short-seller reports or allegations (detail claims)
â”‚   - Regulatory investigations or lawsuits
â”‚   - Product failures or recalls
â”‚   - Operational issues or guidance cuts
â”‚   - Supply chain disruptions
â”‚   - Management turnover (departures)
â”‚   - Competitive threats or lost business
â”‚   
â”‚   **Risk Factors (from 10-K + News):**
â”‚   
â”‚   **Business Risks:**
â”‚   - Customer concentration
â”‚   - Technology obsolescence
â”‚   - Competitive intensity
â”‚   - Market saturation
â”‚   
â”‚   **Financial Risks:**
â”‚   - Leverage levels
â”‚   - FX exposure
â”‚   - Interest rate sensitivity
â”‚   - Commodity price exposure
â”‚   
â”‚   **Operational Risks:**
â”‚   - Key person dependencies
â”‚   - Cybersecurity threats
â”‚   - IT system failures
â”‚   - Supply chain vulnerabilities
â”‚   
â”‚   **Regulatory/Legal Risks:**
â”‚   - Pending litigation
â”‚   - Regulatory changes (potential impact)
â”‚   - Tax disputes
â”‚   - Compliance issues
â”‚   
â”‚   **Reputational/ESG Risks:**
â”‚   - Controversies (labor, environment, ethics)
â”‚   - Social media backlash
â”‚   - Brand damage incidents
â”‚   
â”‚   **Governance Concerns:**
â”‚   - Board independence/diversity
â”‚   - Executive compensation alignment
â”‚   - Related party transactions
â”‚   - Accounting quality questions
â”‚   
â”‚   For each risk: Rate severity (Low/Medium/High)
â”‚   Provide recent examples or evidence
â”‚   
â”‚   Target: 1500-1800 words
â”œâ”€ Critic Focus:
â”‚   - All material news covered?
â”‚   - Short-seller claims addressed objectively?
â”‚   - Risk assessment thorough and balanced?
â”‚   - Sources credible and recent?
â””â”€ Budget: 180K tokens, 3 iterations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SECTION 8: OVERALL ASSESSMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@section-agent-overall-assessment:
â”œâ”€ Dependencies: ALL previous sections (1-7) complete
â”œâ”€ Initial Retrieval:
â”‚   - Read all completed sections
â”‚   - SQLite: full dataset for synthesis
â”‚   - Knowledge Graph: holistic company view
â”‚   - Vector Store: query for "strategic", "outlook", "recommendation"
â”œâ”€ Draft Prompt: |
â”‚   Synthesize all prior analysis into overall assessment:
â”‚   
â”‚   **Strategic Position:**
â”‚   - Where does company stand in its industry?
â”‚   - Competitive position (leader/challenger/niche)
â”‚   - Strategic direction (offense/defense/transition)
â”‚   
â”‚   **SWOT Analysis:**
â”‚   
â”‚   **Strengths:**
â”‚   - Top 3-5 with specific evidence
â”‚   - What do they do better than anyone?
â”‚   
â”‚   **Weaknesses:**
â”‚   - Top 3-5 vulnerabilities
â”‚   - Where are they exposed?
â”‚   
â”‚   **Opportunities:**
â”‚   - Growth avenues (organic/inorganic)
â”‚   - Market expansion possibilities
â”‚   - Innovation potential
â”‚   
â”‚   **Threats:**
â”‚   - Competitive threats
â”‚   - Disruption risks
â”‚   - Macro headwinds
â”‚   
â”‚   **Bull Case (Optimistic Scenario):**
â”‚   - What would drive outperformance?
â”‚   - Key assumptions that must hold
â”‚   - Potential upside (% or price target)
â”‚   - Probability assessment
â”‚   
â”‚   **Bear Case (Pessimistic Scenario):**
â”‚   - What could go wrong?
â”‚   - Key risk that materializes
â”‚   - Potential downside (% or price target)
â”‚   - Probability assessment
â”‚   
â”‚   **Base Case (Most Likely):**
â”‚   - Expected trajectory
â”‚   - Fair value estimate
â”‚   - Return potential vs risk-free rate
â”‚   
â”‚   **Watch Points (Areas for Continued Monitoring):**
â”‚   - Key metrics to track quarterly
â”‚   - Upcoming events or catalysts
â”‚   - Signposts that would change thesis
â”‚   - Further diligence areas
â”‚   
â”‚   **Investment Recommendation:**
â”‚   - Buy / Hold / Sell (with conviction level)
â”‚   - Target price (12-month)
â”‚   - Risk/reward assessment
â”‚   - Portfolio fit (who should own this?)
â”‚   
â”‚   Target: 1500-2000 words
â”œâ”€ Critic Focus:
â”‚   - Does assessment synthesize all prior sections coherently?
â”‚   - Bull/bear cases specific and realistic?
â”‚   - Recommendation clear and justified?
â”‚   - Watch points actionable?
â””â”€ Budget: 180K tokens, 3 iterations
```

### Phase 3: Synthesis & Final Polish

```markdown
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FINAL ASSEMBLY & POLISH
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@synthesis-agent:
â”œâ”€ Dependencies: ALL section agents complete
â”œâ”€ Budget: 200K tokens
â””â”€ Process:

STEP 1: COMPILE REPORT
â”œâ”€ Load all 8 completed sections
â”œâ”€ Assemble in order with proper formatting using jinja2
â”œâ”€ Generate table of contents with page numbers
â”œâ”€ Add title page with:
â”‚   - Company name and ticker
â”‚   - Report date
â”‚   - "For Informational Purposes Only" disclaimer
â”œâ”€ Add appendices:
â”‚   - Source bibliography (all sources cited)
â”‚   - Definitions/glossary
â”‚   - Detailed financial tables
â”‚   - Additional charts
â””â”€ Save to ./reports/TICKER_research_report_DRAFT.md

STEP 2: FINAL CRITIC EVALUATION
â”œâ”€ Prompt: |
â”‚   Review the complete report as a senior portfolio manager would:
â”‚   
â”‚   **Content Critique:**
â”‚   - Is narrative arc coherent start to finish?
â”‚   - Do sections flow logically?
â”‚   - Any contradictions between sections?
â”‚   - Are key questions answered?
â”‚   - Appropriate depth for each topic?
â”‚   
â”‚   **Style Critique:**
â”‚   - Professional, analytical Wall Street tone maintained?
â”‚   - Appropriate for institutional investor audience?
â”‚   - Clear, concise prose?
â”‚   - Jargon explained when necessary?
â”‚   
â”‚   **Technical Critique:**
â”‚   - Data accuracy spot checks
â”‚   - Calculations verified
â”‚   - Citations complete
â”‚   - Charts/tables properly labeled
â”‚   
â”‚   **Repetition Check:**
â”‚   - Identify any redundant content between sections
â”‚   - Flag for removal or consolidation
â”‚   
â”‚   **Gap Check:**
â”‚   - Any obvious omissions?
â”‚   - Topics that deserve more coverage?
â”‚   - Questions left unanswered?
â”‚   
â”‚   Provide:
â”‚   - Overall quality score (0-100)
â”‚   - List of specific issues to fix
â”‚   - Prioritized by severity (Critical/Important/Minor)
â”œâ”€ Output: Final critique saved to ./critique/final_report_critique.json
â””â”€ If score < 85: Proceed to STEP 3; Else: Proceed to STEP 4

STEP 3: FINAL REWRITE & POLISH
â”œâ”€ Address all Critical and Important issues from critique
â”œâ”€ Remove repetition:
â”‚   - If same fact appears in multiple sections, keep most relevant, cross-reference others
â”‚   - Consolidate overlapping analysis
â”œâ”€ Improve narrative flow:
â”‚   - Add transition sentences between sections
â”‚   - Ensure consistent terminology
â”‚   - Unify voice and tone
â”œâ”€ Enhance clarity:
â”‚   - Simplify complex sentences
â”‚   - Define technical terms on first use
â”‚   - Add subheadings for easier navigation
â”œâ”€ Verify all data:
â”‚   - Cross-check key numbers against sources
â”‚   - Ensure calculations are correct
â”‚   - Update any stale data
â””â”€ Save polished version to ./reports/TICKER_research_report_FINAL.md

STEP 4: GENERATE OUTPUTS
â”œâ”€ Create PDF version (if possible):
â”‚   - Professional formatting
â”‚   - Page numbers, headers, footers
â”‚   - Embedded charts and tables
â”‚   - Save to ./reports/TICKER_research_report_FINAL.pdf
â”œâ”€ Create executive summary (2-page):
â”‚   - Company snapshot
â”‚   - Investment thesis
â”‚   - Key metrics table
â”‚   - Recommendation with price target
â”‚   - Top risks
â”‚   - Save to ./reports/TICKER_executive_summary.md
â”œâ”€ Create data supplement (Excel or CSV):
â”‚   - All financial data in structured format
â”‚   - Comparable company tables
â”‚   - Historical data for charts
â”‚   - Save to ./reports/TICKER_data_supplement.xlsx
â””â”€ Generate metadata file:
    {
      "ticker": "AAPL",
      "report_date": "2025-01-14",
      "total_pages": 24,
      "sections": 8,
      "total_tokens_used": 1847000,
      "total_time_minutes": 28,
      "quality_score": 91,
      "data_sources": 47,
      "recommendation": "Buy",
      "price_target": 245.00,
      "analysts": ["evergreen", "section", "synthesis"]
    }

FINAL OUTPUT:
Present to user:
- Link to final report (markdown and PDF)
- Executive summary
- Key findings summary
- Report metadata
- Invitation for feedback or follow-up questions
```

## Orchestrator Implementation

python

```python
# Pseudo-code for orchestrator

class TaskQueue:
    def __init__(self):
        self.tasks = {}  # task_id -> Task object
        self.dependency_graph = {}  # DAG representation
        
    def add_task(self, task):
        self.tasks[task.id] = task
        self.dependency_graph[task.id] = task.dependencies
        
    def get_ready_tasks(self):
        """Return all tasks with satisfied dependencies"""
        ready = []
        for task_id, task in self.tasks.items():
            if task.status == "not_ready":
                deps_satisfied = all(
                    self.tasks[dep].status == "complete" 
                    for dep in task.dependencies
                )
                if deps_satisfied:
                    task.status = "ready"
                    ready.append(task)
        return ready
    
    def mark_complete(self, task_id):
        self.tasks[task_id].status = "complete"
        # Check if this enables new tasks
        self.plan_new_tasks(task_id)
    
    def plan_new_tasks(self, completed_task_id):
        """
        After task completes, decide if new research needed
        Example: If news search finds major lawsuit, 
        spawn new task to deep-dive on legal risks
        """
        completed_task = self.tasks[completed_task_id]
        
        # Analyze output
        if completed_task.name == "evergreen-5":  # News search
            # Check if any bombshell news
            if self.detect_material_event(completed_task.output):
                # Spawn additional investigation task
                new_task = Task(
                    name="deep-dive-legal",
                    dependencies=["evergreen-5"],
                    prompt="Investigate recent lawsuit in detail...",
                    budget=100000
                )
                self.add_task(new_task)

async def orchestrator_main(ticker):
    queue = TaskQueue()
    
    # Phase 1: Add all evergreen tasks (no dependencies)
    for evergreen in EVERGREEN_TASKS:
        queue.add_task(evergreen)
    
    # Phase 2: Add section tasks (depend on evergreens)
    for section in SECTION_TASKS:
        section.dependencies = [e.id for e in EVERGREEN_TASKS]
        queue.add_task(section)
    
    # Phase 3: Add synthesis (depends on all sections)
    synthesis = SynthesisTask(
        dependencies=[s.id for s in SECTION_TASKS]
    )
    queue.add_task(synthesis)
    
    # Main execution loop
    while not queue.all_complete():
        ready_tasks = queue.get_ready_tasks()
        
        if not ready_tasks:
            # Wait for running tasks to complete
            await asyncio.sleep(1)
            continue
        
        # Launch all ready tasks in parallel
        running = []
        for task in ready_tasks:
            task.status = "running"
            running.append(execute_subagent(task))
        
        # Wait for next task to complete
        done, pending = await asyncio.wait(
            running, 
            return_when=asyncio.FIRST_COMPLETED
        )
        
        for completed in done:
            task = completed.result()
            queue.mark_complete(task.id)
            print(f"âœ… {task.name} complete")
    
    print("ğŸ‰ All tasks complete!")
    return queue.tasks["synthesis"].output
```