#!/usr/bin/env python3
"""
Technical Analysis Research Phase

Performs technical analysis using charts and indicators from the MCP server.

Usage:
    ./skills/research_technical.py SYMBOL [--work-dir DIR]

    If --work-dir is not specified, creates work/SYMBOL_YYYYMMDD automatically.

Examples:
    ./skills/research_technical.py INTC
    ./skills/research_technical.py AAPL --work-dir custom/directory

Output:
    - Creates 01_technical/ directory in work directory
    - chart.png - Stock chart with technical indicators
    - technical_analysis.json - Technical indicators data
    - peers_list.json - List of peer companies
"""

import sys
import os
import argparse
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Financial data libraries
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import talib

# Load environment for OpenBB
from dotenv import load_dotenv
load_dotenv()

# OpenBB for peer data
from openbb import obb

# Import configuration
from config import (
    MAX_PEERS_TO_FETCH,
    SMA_SHORT_PERIOD,
    SMA_MEDIUM_PERIOD,
    SMA_LONG_PERIOD,
    MA_WEEKLY_SHORT,
    MA_WEEKLY_LONG,
    RSI_PERIOD,
    MACD_FAST_PERIOD,
    MACD_SLOW_PERIOD,
    MACD_SIGNAL_PERIOD,
    ATR_PERIOD,
    BOLLINGER_PERIOD,
    BOLLINGER_STD_DEV,
    CHART_HISTORY_YEARS,
    CHART_HISTORY_DAYS,
    CHART_WIDTH,
    CHART_HEIGHT,
    CHART_SCALE,
    VOLUME_AVERAGE_DAYS,
    DATE_FORMAT_FILE,
    CLAUDE_MODEL,
)

# Import utilities
from utils import (
    setup_logging,
    validate_symbol,
    ensure_directory,
)

# Set up logging
logger = setup_logging(__name__)


# ============================================================================
# Peer Lookup Helper Functions
# ============================================================================

def get_peers_finnhub(symbol: str) -> Tuple[bool, Dict[str, List], Optional[str]]:
    """
    Get peer companies using Finnhub API.

    Fetches peer company data using Finnhub's GICS sub-industry classification
    and enriches it with current market data from yfinance.

    Args:
        symbol: Stock ticker symbol

    Returns:
        A tuple containing:
            - success (bool): True if peer data was successfully retrieved
            - peers_data (dict): Dictionary with keys 'symbol', 'name', 'price', 'market_cap'
            - error (str or None): Error message if failed, None otherwise

    Example:
        >>> success, peers, error = get_peers_finnhub('AAPL')
        >>> if success:
        ...     print(f"Found {len(peers['symbol'])} peers")
    """
    import os

    try:
        import finnhub

        api_key = os.getenv('FINNHUB_API_KEY')
        if not api_key:
            return False, {}, "FINNHUB_API_KEY not set in environment"

        client = finnhub.Client(api_key=api_key)

        # Get peer tickers (uses GICS sub-industry classification)
        peer_symbols = client.company_peers(symbol)

        # Remove the target symbol if it's in the list
        peer_symbols = [s for s in peer_symbols if s != symbol]

        if not peer_symbols:
            return False, {}, "Finnhub returned no peers"

        logger.info(f"Found {len(peer_symbols)} potential peers from Finnhub: {', '.join(peer_symbols[:5])}...")
        print(f"  Found {len(peer_symbols)} potential peers from Finnhub: {', '.join(peer_symbols[:5])}...")

        # Enrich with yfinance data
        peers_data: Dict[str, List] = {
            'symbol': [],
            'name': [],
            'price': [],
            'market_cap': []
        }

        for peer in peer_symbols[:MAX_PEERS_TO_FETCH]:
            try:
                ticker = yf.Ticker(peer)
                info = ticker.info

                peers_data['symbol'].append(peer)
                peers_data['name'].append(info.get('longName', peer))
                price = info.get('currentPrice') or info.get('regularMarketPrice', 0.0)
                peers_data['price'].append(float(price) if price else 0.0)
                peers_data['market_cap'].append(info.get('marketCap', 0))

            except (KeyError, ValueError, AttributeError) as e:
                logger.debug(f"Could not fetch data for {peer}: {e}")
                print(f"  ⚠ Could not fetch data for {peer}: {e}")
                continue
            except Exception as e:
                logger.warning(f"Unexpected error fetching {peer}: {e}")
                continue

        if not peers_data['symbol']:
            return False, {}, "Could not enrich any peers with market data"

        logger.info(f"Enriched {len(peers_data['symbol'])} peers with market data")
        print(f"  ✓ Enriched {len(peers_data['symbol'])} peers with market data")
        return True, peers_data, None

    except ImportError:
        return False, {}, "finnhub-python not installed (pip install finnhub-python)"
    except Exception as e:
        error_msg = str(e)
        # Check for rate limit
        if '429' in error_msg or 'rate limit' in error_msg.lower():
            logger.error(f"Finnhub rate limit exceeded: {error_msg}")
            return False, {}, f"Finnhub rate limit exceeded: {error_msg}"
        logger.error(f"Finnhub error: {error_msg}", exc_info=True)
        return False, {}, f"Finnhub error: {error_msg}"


def get_peers_openbb(symbol: str) -> Tuple[bool, Dict, Optional[str]]:
    """
    Get peer companies using OpenBB/FMP.

    Args:
        symbol: Stock ticker symbol

    Returns:
        A tuple containing:
            - success (bool): True if peer data was successfully retrieved
            - peers_data (dict): Peer company data dictionary
            - error (str or None): Error message if failed, None otherwise

    Example:
        >>> success, peers, error = get_peers_openbb('TSLA')
        >>> if success:
        ...     print("OpenBB peers retrieved")
    """
    import os

    try:
        pat = os.getenv('OPENBB_PAT')
        if not pat:
            return False, {}, "OPENBB_PAT not set in environment"

        # Login with PAT
        try:
            obb.user.credentials.openbb_pat = pat
        except Exception as e:
            logger.error(f"Could not login with PAT: {e}")
            return False, {}, f"Could not login with PAT: {e}"

        # Get peers using FMP provider
        peers_result = obb.equity.compare.peers(symbol=symbol, provider='fmp')
        peers_data = peers_result.to_dict()

        if not peers_data:
            return False, {}, "OpenBB/FMP returned empty results"

        logger.info("OpenBB/FMP returned peers")
        print(f"  ✓ OpenBB/FMP returned peers")
        return True, peers_data, None

    except ImportError:
        return False, {}, "OpenBB not installed (pip install openbb)"
    except Exception as e:
        error_msg = str(e)
        # Check if it's a subscription issue
        if 'subscription' in error_msg.lower() or 'plan' in error_msg.lower():
            logger.warning(f"FMP peers endpoint requires paid subscription: {error_msg}")
            return False, {}, f"FMP peers endpoint requires paid subscription: {error_msg}"
        logger.error(f"OpenBB/FMP error: {error_msg}", exc_info=True)
        return False, {}, f"OpenBB/FMP error: {error_msg}"


def get_peers_with_fallback(symbol: str) -> Tuple[Dict[str, List], str, Dict[str, Optional[str]]]:
    """
    Get peer companies with automatic fallback chain.

    Tries multiple providers in sequence: Finnhub -> OpenBB+FMP

    Args:
        symbol: Stock ticker symbol

    Returns:
        A tuple containing:
            - peers_data (dict): Dictionary with peer data (keys: symbol, name, price, market_cap)
            - provider_used (str): Name of successful provider ('Finnhub', 'OpenBB+FMP', or 'none')
            - all_errors (dict): Dictionary mapping provider names to error messages

    Example:
        >>> peers, provider, errors = get_peers_with_fallback('AAPL')
        >>> if provider != 'none':
        ...     print(f"Found peers using {provider}")
    """
    all_errors: Dict[str, Optional[str]] = {}

    # Try Finnhub first
    logger.info("[1/2] Trying Finnhub for peer detection...")
    print(f"[1/2] Trying Finnhub for peer detection...")
    success, peers_data, error = get_peers_finnhub(symbol)
    all_errors['finnhub'] = error

    if success and peers_data:
        logger.info("Finnhub succeeded")
        print(f"✓ Finnhub succeeded")
        return peers_data, 'Finnhub', all_errors
    else:
        logger.info(f"Finnhub failed: {error}")
        print(f"✗ Finnhub failed: {error}")

    # Try OpenBB+FMP second
    logger.info("[2/2] Trying OpenBB+FMP for peer detection...")
    print(f"[2/2] Trying OpenBB+FMP for peer detection...")
    success, peers_data, error = get_peers_openbb(symbol)
    all_errors['openbb'] = error

    if success and peers_data:
        logger.info("OpenBB+FMP succeeded")
        print(f"✓ OpenBB+FMP succeeded")
        return peers_data, 'OpenBB+FMP', all_errors
    else:
        logger.info(f"OpenBB+FMP failed: {error}")
        print(f"✗ OpenBB+FMP failed: {error}")

    # All providers failed
    logger.warning("All peer providers failed")
    return {'symbol': [], 'name': [], 'price': [], 'market_cap': []}, 'none', all_errors


# ============================================================================
# Chart and Technical Analysis Functions
# ============================================================================

def save_chart(symbol: str, work_dir: Path) -> bool:
    """
    Generate and save stock chart with technical indicators.

    Creates a multi-panel chart showing:
    - Candlestick price chart with moving averages
    - Volume overlay
    - Relative strength vs S&P 500

    Args:
        symbol: Stock ticker symbol
        work_dir: Work directory path

    Returns:
        True if chart was successfully generated and saved, False otherwise

    Example:
        >>> from pathlib import Path
        >>> success = save_chart('AAPL', Path('work/AAPL_20260116'))
    """
    try:
        logger.info(f"Generating stock chart for {symbol}...")
        print(f"Generating stock chart for {symbol}...")

        # Download weekly data
        symbol_df = yf.download(symbol, interval="1wk", period=f"{CHART_HISTORY_YEARS}y", progress=False)
        spx_df = yf.download("^GSPC", interval="1wk", period=f"{CHART_HISTORY_YEARS}y", progress=False)

        if symbol_df.empty:
            logger.error(f"No data available for {symbol}")
            print(f"❌ No data available for {symbol}")
            return False

        # Flatten multi-index columns if present
        if isinstance(symbol_df.columns, pd.MultiIndex):
            symbol_df.columns = symbol_df.columns.get_level_values(0)
        if isinstance(spx_df.columns, pd.MultiIndex):
            spx_df.columns = spx_df.columns.get_level_values(0)

        # Compute moving averages
        symbol_df['MA13'] = symbol_df['Close'].rolling(window=MA_WEEKLY_SHORT).mean()
        symbol_df['MA52'] = symbol_df['Close'].rolling(window=MA_WEEKLY_LONG).mean()

        # Compute relative strength vs SPX
        relative = (symbol_df['Close'] / spx_df['Close']).values
        symbol_df['Rel_SPX'] = relative

        # Create figure with subplots
        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            row_heights=[0.75, 0.25],
            vertical_spacing=0.02,
            specs=[[{"secondary_y": True}], [{}]]
        )

        # Candlestick chart
        colors = ['green' if row['Close'] >= row['Open'] else 'red'
                  for idx, row in symbol_df.iterrows()]

        fig.add_trace(
            go.Candlestick(
                x=symbol_df.index,
                open=symbol_df['Open'],
                high=symbol_df['High'],
                low=symbol_df['Low'],
                close=symbol_df['Close'],
                increasing_line_color='green',
                decreasing_line_color='red',
                name=symbol
            ),
            row=1, col=1
        )

        # Moving averages
        fig.add_trace(
            go.Scatter(x=symbol_df.index, y=symbol_df['MA13'],
                       mode='lines', name='MA13', line=dict(color='blue', width=1)),
            row=1, col=1
        )

        fig.add_trace(
            go.Scatter(x=symbol_df.index, y=symbol_df['MA52'],
                       mode='lines', name='MA52', line=dict(color='orange', width=1)),
            row=1, col=1
        )

        # Volume
        fig.add_trace(
            go.Bar(x=symbol_df.index, y=symbol_df['Volume'],
                   name='Volume', marker_color=colors, opacity=0.5),
            row=1, col=1, secondary_y=True
        )

        # Relative strength
        fig.add_trace(
            go.Scatter(x=symbol_df.index, y=symbol_df['Rel_SPX'],
                       mode='lines', name='Rel. to S&P500',
                       line=dict(color='purple', width=1)),
            row=2, col=1
        )

        # Update layout
        fig.update_layout(
            title=f'{symbol} - Weekly Chart',
            xaxis_rangeslider_visible=False,
            height=CHART_HEIGHT,
            width=CHART_WIDTH,
            showlegend=True
        )

        fig.update_yaxes(title_text="Price", row=1, col=1)
        fig.update_yaxes(title_text="Volume", row=1, col=1, secondary_y=True)
        fig.update_yaxes(title_text="Relative Strength", row=2, col=1)

        # Save chart
        output_dir = Path(work_dir) / '01_technical'
        ensure_directory(output_dir)

        chart_path = output_dir / 'chart.png'
        fig.write_image(str(chart_path), scale=CHART_SCALE)

        logger.info(f"Saved chart to: {chart_path}")
        print(f"✓ Saved chart to: {chart_path}")
        return True

    except (ValueError, KeyError, AttributeError) as e:
        logger.error(f"Error generating chart: {e}", exc_info=True)
        print(f"❌ Error generating chart: {e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error generating chart: {e}", exc_info=True)
        print(f"❌ Error generating chart: {e}")
        return False


def save_technical_analysis(symbol: str, work_dir: Path) -> bool:
    """
    Generate and save technical analysis indicators.

    Calculates and saves various technical indicators including:
    - Simple Moving Averages (20, 50, 200 day)
    - RSI (Relative Strength Index)
    - MACD (Moving Average Convergence Divergence)
    - ATR (Average True Range)
    - Bollinger Bands

    Args:
        symbol: Stock ticker symbol
        work_dir: Work directory path

    Returns:
        True if analysis was successful, False otherwise

    Example:
        >>> from pathlib import Path
        >>> success = save_technical_analysis('TSLA', Path('work/TSLA_20260116'))
    """
    try:
        logger.info(f"Running technical analysis for {symbol}...")
        print(f"Running technical analysis for {symbol}...")

        # Download daily data for technical indicators
        df = yf.download(symbol, period=f"{CHART_HISTORY_DAYS}d", progress=False)

        if df.empty:
            logger.error(f"No data available for {symbol}")
            print(f"❌ No data available for {symbol}")
            return False

        # Flatten multi-index columns if present
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)

        # Calculate technical indicators using TA-Lib
        # Convert to numpy arrays and ensure they are 1D
        close = np.array(df['Close'].values, dtype=np.float64).flatten()
        high = np.array(df['High'].values, dtype=np.float64).flatten()
        low = np.array(df['Low'].values, dtype=np.float64).flatten()
        volume = np.array(df['Volume'].values, dtype=np.float64).flatten()

        # Moving averages
        sma_20 = talib.SMA(close, timeperiod=SMA_SHORT_PERIOD)
        sma_50 = talib.SMA(close, timeperiod=SMA_MEDIUM_PERIOD)
        sma_200 = talib.SMA(close, timeperiod=SMA_LONG_PERIOD)

        # RSI
        rsi = talib.RSI(close, timeperiod=RSI_PERIOD)

        # MACD
        macd, macd_signal, macd_hist = talib.MACD(close,
                                                    fastperiod=MACD_FAST_PERIOD,
                                                    slowperiod=MACD_SLOW_PERIOD,
                                                    signalperiod=MACD_SIGNAL_PERIOD)

        # ATR
        atr = talib.ATR(high, low, close, timeperiod=ATR_PERIOD)

        # Bollinger Bands
        bb_upper, bb_middle, bb_lower = talib.BBANDS(close,
                                                       timeperiod=BOLLINGER_PERIOD,
                                                       nbdevup=BOLLINGER_STD_DEV,
                                                       nbdevdn=BOLLINGER_STD_DEV,
                                                       matype=0)

        # Get latest values - convert immediately to floats
        price_val = float(close[-1])
        rsi_val = float(rsi[-1]) if not np.isnan(rsi[-1]) else 0.0
        atr_val = float(atr[-1]) if not np.isnan(atr[-1]) else 0.0
        macd_val = float(macd[-1]) if not np.isnan(macd[-1]) else 0.0
        macd_sig_val = float(macd_signal[-1]) if not np.isnan(macd_signal[-1]) else 0.0
        macd_hist_val = float(macd_hist[-1]) if not np.isnan(macd_hist[-1]) else 0.0
        sma20_val = float(sma_20[-1]) if not np.isnan(sma_20[-1]) else 0.0
        sma50_val = float(sma_50[-1]) if not np.isnan(sma_50[-1]) else 0.0
        sma200_val = float(sma_200[-1]) if not np.isnan(sma_200[-1]) else 0.0
        bb_upper_val = float(bb_upper[-1]) if not np.isnan(bb_upper[-1]) else 0.0
        bb_middle_val = float(bb_middle[-1]) if not np.isnan(bb_middle[-1]) else 0.0
        bb_lower_val = float(bb_lower[-1]) if not np.isnan(bb_lower[-1]) else 0.0
        vol_val = float(volume[-20:].mean())

        # Trend analysis (values already converted to 0.0 if NaN)
        above_20sma = price_val > sma20_val if sma20_val > 0 else False
        above_50sma = price_val > sma50_val if sma50_val > 0 else False
        above_200sma = price_val > sma200_val if sma200_val > 0 else False
        sma_20_50_bullish = sma20_val > sma50_val if (sma20_val > 0 and sma50_val > 0) else False
        sma_50_200_bullish = sma50_val > sma200_val if (sma50_val > 0 and sma200_val > 0) else False
        macd_bullish = macd_val > macd_sig_val

        # Create analysis text
        analysis_text = f"""
Technical Analysis for {symbol}:

Trend Analysis:
- Above 20 SMA: {'✅' if above_20sma else '❌'}
- Above 50 SMA: {'✅' if above_50sma else '❌'}
- Above 200 SMA: {'✅' if above_200sma else '❌'}
- 20/50 SMA Bullish Cross: {'✅' if sma_20_50_bullish else '❌'}
- 50/200 SMA Bullish Cross: {'✅' if sma_50_200_bullish else '❌'}

Momentum:
- RSI (14): {rsi_val:.2f}
- MACD Bullish: {'✅' if macd_bullish else '❌'}

Latest Price: ${price_val:.2f}
Average True Range (14): {atr_val:.2f}
Average Volume (20D): {vol_val:,.0f}
"""

        # Save as JSON
        output_dir = Path(work_dir) / '01_technical'
        ensure_directory(output_dir)

        analysis_data = {
            'symbol': symbol,
            'timestamp': datetime.now().isoformat(),
            'latest_price': price_val,
            'indicators': {
                'sma_20': sma20_val if sma20_val > 0 else None,
                'sma_50': sma50_val if sma50_val > 0 else None,
                'sma_200': sma200_val if sma200_val > 0 else None,
                'rsi_14': rsi_val if rsi_val > 0 else None,
                'macd': macd_val,
                'macd_signal': macd_sig_val,
                'macd_histogram': macd_hist_val,
                'atr_14': atr_val if atr_val > 0 else None,
                'bollinger_upper': bb_upper_val if bb_upper_val > 0 else None,
                'bollinger_middle': bb_middle_val if bb_middle_val > 0 else None,
                'bollinger_lower': bb_lower_val if bb_lower_val > 0 else None,
                'avg_volume_20d': vol_val
            },
            'trend_signals': {
                'above_20sma': above_20sma,
                'above_50sma': above_50sma,
                'above_200sma': above_200sma,
                'sma_20_50_bullish': sma_20_50_bullish,
                'sma_50_200_bullish': sma_50_200_bullish,
                'macd_bullish': macd_bullish
            },
            'analysis': analysis_text.strip()
        }

        analysis_path = output_dir / 'technical_analysis.json'
        with analysis_path.open('w') as f:
            json.dump(analysis_data, f, indent=2)

        logger.info(f"Saved technical analysis to: {analysis_path}")
        print(f"✓ Saved technical analysis to: {analysis_path}")

        # Print the analysis
        print("\nTechnical Analysis Summary:")
        print("-" * 60)
        print(analysis_text)
        print("-" * 60)

        return True

    except (ValueError, KeyError, AttributeError) as e:
        logger.error(f"Error in technical analysis: {e}", exc_info=True)
        print(f"❌ Error in technical analysis: {e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error in technical analysis: {e}", exc_info=True)
        print(f"❌ Error in technical analysis: {e}")
        return False


def filter_peers_by_industry(
    symbol: str,
    company_name: str,
    industry: str,
    peers_data: Dict[str, List]
) -> Tuple[Optional[Dict[str, List]], Optional[str]]:
    """
    Use Claude API to filter peers to only true industry peers.

    Leverages Claude's reasoning to identify companies that are actual industry
    peers versus unrelated companies that may be returned by basic classification.

    Args:
        symbol: Target company ticker
        company_name: Target company name
        industry: Target company industry
        peers_data: Dictionary with 'symbol' and 'name' lists

    Returns:
        A tuple containing:
            - filtered_peers_data (dict or None): Filtered peer data, None if filtering failed
            - rationale_text (str or None): Explanation of filtering decisions, None if failed

    Example:
        >>> peers = {'symbol': ['AAPL', 'MSFT'], 'name': ['Apple', 'Microsoft']}
        >>> filtered, rationale = filter_peers_by_industry('AAPL', 'Apple Inc.', 'Technology', peers)
    """
    import os

    try:
        # Import Anthropic here to avoid loading if not needed
        from anthropic import Anthropic

        # Build prompt
        peers_list_text = "\n".join([
            f"- {sym}: {name}"
            for sym, name in zip(peers_data['symbol'], peers_data['name'])
        ])

        # Define structured output schema
        schema = {
            "type": "object",
            "properties": {
                "filtered_peers": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "symbol": {"type": "string"},
                            "name": {"type": "string"},
                            "keep": {"type": "boolean"},
                            "reason": {"type": "string"}
                        },
                        "required": ["symbol", "name", "keep", "reason"]
                    }
                }
            },
            "required": ["filtered_peers"]
        }

        prompt = f"""I am analyzing {symbol} ({company_name}), which operates in the {industry} industry.

My market data provider gave me this list of potential peer companies:

{peers_list_text}

Please filter this list to include ONLY companies that are:
1. Primarily engaged in the same or closely adjacent industries as {company_name}
2. Comparable in business model and operations

Exclude companies that are:
- In completely different industries
- Vertically integrated suppliers or customers (not peers)

For EACH company in the list above, you must provide:
- symbol: the ticker symbol
- name: the company name
- keep: true if it's a peer, false if not
- reason: brief explanation (one sentence)

You must evaluate ALL {len(peers_data['symbol'])} companies from the list."""

        # Call Claude API with structured output
        api_key = os.environ.get('ANTHROPIC_API_KEY')
        if not api_key:
            logger.warning("ANTHROPIC_API_KEY not set, skipping peer filtering")
            print("⚠ Warning: ANTHROPIC_API_KEY not set, skipping peer filtering")
            return None, None

        client = Anthropic(api_key=api_key)

        try:
            response = client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=4000,
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        }
                    ]
                }],
                response_format={
                    "type": "json_schema",
                    "json_schema": {
                        "name": "peer_filter_result",
                        "strict": True,
                        "schema": schema
                    }
                }
            )
        except TypeError:
            # Fallback if response_format not supported in this SDK version
            logger.info("Using prompt-based JSON (SDK doesn't support response_format)")
            print("  Note: Using prompt-based JSON (SDK doesn't support response_format)")
            response = client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=4000,
                system="You are a financial analyst. Respond ONLY with valid JSON matching the requested schema. Do not include any explanatory text, markdown formatting, or code blocks.",
                messages=[{
                    "role": "user",
                    "content": prompt + f"\n\nRespond with JSON matching this schema:\n{json.dumps(schema, indent=2)}"
                }]
            )

        # Parse structured JSON response
        response_text = response.content[0].text.strip()

        # Remove markdown code blocks if present
        if response_text.startswith('```'):
            lines = response_text.split('\n')
            if lines[0].strip() == '```json':
                response_text = '\n'.join(lines[1:-1])
            else:
                response_text = '\n'.join(lines[1:-1])

        result = json.loads(response_text)

        # Build filtered peers data
        filtered_symbols = []
        filtered_names = []
        filtered_prices = []
        filtered_market_caps = []
        rationale_lines = []

        for peer_decision in result['filtered_peers']:
            symbol_val = peer_decision['symbol']
            name_val = peer_decision['name']
            keep = peer_decision['keep']
            reason = peer_decision['reason']

            # Find index in original data
            try:
                idx = peers_data['symbol'].index(symbol_val)
            except ValueError:
                print(f"⚠ Warning: {symbol_val} not found in original peers data")
                continue

            if keep:
                filtered_symbols.append(peers_data['symbol'][idx])
                filtered_names.append(peers_data['name'][idx])
                if 'price' in peers_data:
                    filtered_prices.append(peers_data['price'][idx])
                if 'market_cap' in peers_data:
                    filtered_market_caps.append(peers_data['market_cap'][idx])
                rationale_lines.append(f"✓ KEEP {symbol_val}: {reason}")
            else:
                rationale_lines.append(f"✗ EXCLUDE {symbol_val}: {reason}")

        # Build filtered peers data structure
        filtered_peers = {
            'symbol': filtered_symbols,
            'name': filtered_names
        }
        if 'price' in peers_data:
            filtered_peers['price'] = filtered_prices
        if 'market_cap' in peers_data:
            filtered_peers['market_cap'] = filtered_market_caps

        rationale_text = "\n".join(rationale_lines)

        return filtered_peers, rationale_text

    except (KeyError, ValueError, json.JSONDecodeError) as e:
        logger.warning(f"Could not filter peers: {e}")
        print(f"⚠ Warning: Could not filter peers: {e}")
        return None, None
    except Exception as e:
        logger.error(f"Unexpected error filtering peers: {e}", exc_info=True)
        print(f"⚠ Warning: Could not filter peers: {e}")
        return None, None


def save_peers_list(
    symbol: str,
    work_dir: Path,
    custom_peers: Optional[str] = None,
    filter_peers: bool = True
) -> bool:
    """
    Get and save peer companies list.

    Either uses custom peers provided by user or auto-detects peers using
    multiple data providers. Optionally filters peers using Claude API.

    Args:
        symbol: Stock ticker symbol
        work_dir: Work directory path
        custom_peers: Optional comma-separated custom peer tickers
        filter_peers: If True, use Claude API to filter peers by industry

    Returns:
        True if successful, False otherwise

    Example:
        >>> from pathlib import Path
        >>> success = save_peers_list('TSLA', Path('work/TSLA_20260116'))
    """
    import os

    try:
        logger.info(f"Getting peer companies for {symbol}...")
        print(f"Getting peer companies for {symbol}...")

        if custom_peers:
            # Use custom peers provided by user
            peer_symbols = [p.strip().upper() for p in custom_peers.split(',')]
            print(f"✓ Using custom peers: {', '.join(peer_symbols)}")

            # Fetch metadata for each peer using yfinance
            names = []
            prices = []
            market_caps = []

            for peer in peer_symbols:
                try:
                    ticker = yf.Ticker(peer)
                    info = ticker.info
                    names.append(info.get('longName', peer))
                    # Use currentPrice or regularMarketPrice
                    price = info.get('currentPrice') or info.get('regularMarketPrice', 0.0)
                    prices.append(float(price) if price else 0.0)
                    market_caps.append(info.get('marketCap', 0))
                    print(f"  ✓ {peer}: {names[-1]}")
                except Exception as e:
                    print(f"  ⚠ Warning: Could not fetch complete data for {peer}: {e}")
                    names.append(peer)
                    prices.append(0.0)
                    market_caps.append(0)

            # Create peers data structure (same format as OpenBB)
            peers_data = {
                'symbol': peer_symbols,
                'name': names,
                'price': prices,
                'market_cap': market_caps
            }
        else:
            # Auto-detect peers using fallback chain: Finnhub -> OpenBB+FMP
            print(f"Auto-detecting peers for {symbol}...")
            print(f"Fallback chain: Finnhub → OpenBB+FMP\n")

            peers_data, provider_used, all_errors = get_peers_with_fallback(symbol)

            if provider_used == 'none':
                # All providers failed
                print(f"\n⚠ WARNING: Could not auto-detect peers from any provider")
                print(f"\nProvider errors:")
                for provider, error in all_errors.items():
                    if error:
                        print(f"  • {provider}: {error}")
                print(f"\nOptions for future runs:")
                print(f"  1. Provide custom peers: --peers 'SYM1,SYM2,SYM3'")
                print(f"  2. Set FINNHUB_API_KEY in .env (recommended - free tier)")
                print(f"     Get free API key at: https://finnhub.io/register")
                print(f"  3. Set OPENBB_PAT in .env (note: FMP peers requires paid subscription)")
                print(f"\nProceeding with empty peers list...\n")
            else:
                print(f"\n✓ Successfully detected peers using {provider_used}\n")

        # Save to file (same for both paths)
        output_dir = Path(work_dir) / '01_technical'
        ensure_directory(output_dir)

        peers_path = output_dir / 'peers_list.json'
        with peers_path.open('w') as f:
            json.dump(peers_data, f, indent=2)

        logger.info(f"Saved peers list to: {peers_path}")
        print(f"✓ Saved peers list to: {peers_path}")

        # Print peer symbols
        if 'symbol' in peers_data and isinstance(peers_data['symbol'], list):
            peer_symbols_list = peers_data['symbol']
            print(f"✓ Raw peer list ({len(peer_symbols_list)}): {', '.join(peer_symbols_list[:10])}")
        elif 'results' in peers_data and isinstance(peers_data['results'], list):
            peer_symbols_list = [p.get('symbol', 'N/A') for p in peers_data['results']]
            print(f"✓ Found {len(peer_symbols_list)} peers: {', '.join(peer_symbols_list[:10])}")
        elif 'peers_list' in peers_data:
            print(f"✓ Peers: {', '.join(peers_data['peers_list'][:10])}")

        # Apply peer filtering if requested
        if filter_peers:
            logger.info("Filtering peers using Claude API...")
            print(f"\nFiltering peers using Claude API...")

            # Need company overview for industry classification
            overview_path = Path(work_dir) / '02_fundamental' / 'company_overview.json'
            if overview_path.exists():
                with overview_path.open('r') as f:
                    overview = json.load(f)

                company_name = overview.get('company_name', symbol)
                industry = overview.get('industry', 'Unknown')

                print(f"Target company: {company_name}")
                print(f"Industry: {industry}")

                # Filter peers
                filtered_peers, rationale = filter_peers_by_industry(
                    symbol, company_name, industry, peers_data
                )

                if filtered_peers:
                    # Save raw peers as backup
                    raw_peers_path = output_dir / 'peers_list_raw.json'
                    with raw_peers_path.open('w') as f:
                        json.dump(peers_data, f, indent=2)
                    logger.info(f"Saved raw peers to: {raw_peers_path}")
                    print(f"✓ Saved raw peers to: {raw_peers_path}")

                    # Replace with filtered peers
                    with peers_path.open('w') as f:
                        json.dump(filtered_peers, f, indent=2)
                    logger.info(f"Saved filtered peers to: {peers_path}")
                    print(f"✓ Saved filtered peers to: {peers_path}")

                    # Print rationale
                    print("\nFiltering Results:")
                    print("-" * 60)
                    print(rationale)
                    print("-" * 60)

                    original_count = len(peers_data['symbol']) if 'symbol' in peers_data else 0
                    filtered_count = len(filtered_peers['symbol'])
                    print(f"\n✓ Filtered from {original_count} to {filtered_count} peers")
                    print(f"✓ Final peer list: {', '.join(filtered_peers['symbol'])}")
                else:
                    print("⚠ Peer filtering failed, using raw peer list")
            else:
                print(f"⚠ Warning: Company overview not found at {overview_path}")
                print("  Run research_fundamental.py first, or run without --filter-peers")
                print("  Using raw peer list")

        return True

    except (KeyError, ValueError, json.JSONDecodeError) as e:
        logger.error(f"Error getting peers: {e}", exc_info=True)
        print(f"❌ Error getting peers: {e}")
        return False
    except Exception as e:
        logger.error(f"Unexpected error getting peers: {e}", exc_info=True)
        print(f"❌ Error getting peers: {e}")
        return False


def main() -> int:
    """
    Main execution function.

    Returns:
        Exit code (0 for success, 1 for failure)
    """
    parser = argparse.ArgumentParser(
        description='Technical analysis research phase'
    )
    parser.add_argument(
        'symbol',
        help='Stock ticker symbol (e.g., INTC, AAPL, MSFT)'
    )
    parser.add_argument(
        '--work-dir',
        default=None,
        help='Work directory path (default: work/SYMBOL_YYYYMMDD)'
    )
    parser.add_argument(
        '--peers',
        default=None,
        help='Comma-separated list of custom peer tickers to override auto-detection'
    )
    parser.add_argument(
        '--no-filter-peers',
        action='store_true',
        help='Disable peer filtering (filtering is enabled by default)'
    )

    args = parser.parse_args()

    # Normalize symbol
    symbol = validate_symbol(args.symbol)

    # Generate work directory if not specified
    if not args.work_dir:
        date_str = datetime.now().strftime(DATE_FORMAT_FILE)
        work_dir = Path('work') / f'{symbol}_{date_str}'
    else:
        work_dir = Path(args.work_dir)

    # Create work directory if it doesn't exist
    ensure_directory(work_dir)

    print("=" * 60)
    print("Technical Analysis Phase")
    print("=" * 60)
    print(f"Symbol: {symbol}")
    print(f"Work Directory: {work_dir}")
    print("=" * 60)

    success_count = 0
    total_count = 3

    # Task 1: Generate chart
    if save_chart(symbol, work_dir):
        success_count += 1

    # Task 2: Run technical analysis
    if save_technical_analysis(symbol, work_dir):
        success_count += 1

    # Task 3: Get peers list
    filter_peers = not args.no_filter_peers  # Filter by default unless --no-filter-peers
    if save_peers_list(symbol, work_dir, args.peers, filter_peers):
        success_count += 1

    # Summary
    print("\n" + "=" * 60)
    print("Technical Analysis Phase Complete")
    print("=" * 60)
    print(f"Tasks completed: {success_count}/{total_count}")

    if success_count == total_count:
        print("✓ All tasks completed successfully")
        return 0
    elif success_count > 0:
        print(f"⚠ Partial success: {success_count}/{total_count} tasks completed")
        return 0  # Still return success for partial completion
    else:
        print("❌ All tasks failed")
        return 1


if __name__ == '__main__':
    sys.exit(main())
